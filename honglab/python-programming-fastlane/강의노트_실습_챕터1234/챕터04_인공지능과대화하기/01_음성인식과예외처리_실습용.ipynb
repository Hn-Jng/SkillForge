{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<a href='https://cafe.naver.com/jmhonglab'><p style=\"text-align:center;\"><img src='https://lh3.googleusercontent.com/lY3ySXooSmwsq5r-mRi7uiypbo0Vez6pmNoQxMFhl9fmZJkRHu5lO2vo7se_0YOzgmDyJif9fi4_z0o3ZFdwd8NVSWG6Ea80uWaf3pOHpR4GHGDV7kaFeuHR3yAjIJjDgfXMxsvw=w2400'  class=\"center\" width=\"50%\" height=\"50%\"/></p></a>\n",
    "___\n",
    "<center><em>Content Copyright by HongLab, Inc.</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이썬 음성 인식 (Speech Recognition)\n",
    "\n",
    "컴퓨터에 연결된 마이크가 필요합니다. 화상회의 용으로 사용하는 노트북 내장 마이크나 헤드셋 내장 마이크 등이면 충분합니다. 스마트폰용으로 나온 마이크 달린 이어폰을 PC에 연결할 경우에는 연결 단자의 종류가 달라서 마이크가 작동하지 않을 수도 있으니 주의하세요.\n",
    "\n",
    "### 음성 인식의 원리 요약\n",
    "\n",
    "마이크로 입력받은 음성 신호를 분석하기에 좋은 디지털 오디오 데이터로 변환한 후에 기계학습으로 훈련된 모델을 이용하여 문자열로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 필요한 패키지들 설치\n",
    "\n",
    "- [SpeechRecognition](https://github.com/Uberi/speech_recognition#readme)\n",
    "- [PyAudio](http://people.csail.mit.edu/hubert/pyaudio/): 마이크와 스피커를 통한 오디오 입력과 출력\n",
    "\n",
    "윈도우 운영체제에서는 아래와 같이 비교적 쉽게 설치할 수 있습니다.  \n",
    "(미니콘다 파이썬 3.10.0 가상환경 기준)\n",
    "```\n",
    "pip install SpeechRecognition\n",
    "pip install pipwin\n",
    "pipwin install pyaudio\n",
    "```\n",
    "맥에서 PyAudio를 설치하는 방법은 따로 안내해드리겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 음성 인식기 사용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 내 컴퓨터에 마이크가 설치되어 있는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.4\n",
      "0, Microsoft Sound Mapper - Input\n",
      "1, 마이크 배열(Synaptics SmartAudio HD)\n",
      "2, Microsoft Sound Mapper - Output\n",
      "3, 스피커(Synaptics SmartAudio HD)\n",
      "4, 주 사운드 캡처 드라이버\n",
      "5, 마이크 배열(Synaptics SmartAudio HD)\n",
      "6, 주 사운드 드라이버\n",
      "7, 스피커(Synaptics SmartAudio HD)\n",
      "8, 스피커(Synaptics SmartAudio HD)\n",
      "9, 마이크 배열(Synaptics SmartAudio HD)\n",
      "10, Microphone (Conexant HD Audio capture)\n",
      "11, Headphones (Conexant HD Audio headphone)\n",
      "12, Speakers (Conexant HD Audio output)\n",
      "13, Microphone Array (Conexant HD Audio capture)\n",
      "14, 헤드폰 ()\n",
      "15, 머리에 거는 수화기 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(AirPods Pro))\n",
      "16, 머리에 거는 수화기 (@System32\\drivers\\bthhfenum.sys,#2;%1 Hands-Free AG Audio%0\n",
      ";(AirPods Pro))\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# speech_recognition 버전 체크\n",
    "print(sr.__version__)\n",
    "\n",
    "# 가지고 있는 마이크 목록 확인\n",
    "microphone_list = sr.Microphone.list_microphone_names()\n",
    "\n",
    "for index, mic_name in enumerate(microphone_list):\n",
    "    print(f\"{index}, {mic_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 음성 인식을 할 수 있습니다. 여기서는 구글 온라인 인식기를 사용하였습니다. 인터넷이 연결되어 있어야 하며 [사용량에 제한](https://cloud.google.com/speech-to-text/quotas#:~:text=for%20more%20information.-,Content%20Limits,the%20API%20using%20local%20files)이 있을 수도 있습니다. 더 다양한 인식기를 사용하는 예제는 [여기서](https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py) 보실 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음성 인식 대기중\n"
     ]
    },
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     audio \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mlisten(source) \u001b[38;5;66;03m# 일정 크기 이상의 소리가 들리면 녹음합니다.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# with-as 블럭 안에서 정의한 변수인 audio를 블럭 밖에서도 사용할 수 있습니다.\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecognize_google\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mko\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m인식 결과:\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# 음성을 제대로 인식하지 못하는 경우도 시연\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\MZC02-CHAESH\\miniconda3\\envs\\honglab-python\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:263\u001b[0m, in \u001b[0;36mrecognize_legacy\u001b[1;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[0;32m    256\u001b[0m response_text \u001b[38;5;241m=\u001b[39m obtain_transcription(\n\u001b[0;32m    257\u001b[0m     request, timeout\u001b[38;5;241m=\u001b[39mrecognizer\u001b[38;5;241m.\u001b[39moperation_timeout\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    260\u001b[0m output_parser \u001b[38;5;241m=\u001b[39m OutputParser(\n\u001b[0;32m    261\u001b[0m     show_all\u001b[38;5;241m=\u001b[39mshow_all, with_confidence\u001b[38;5;241m=\u001b[39mwith_confidence\n\u001b[0;32m    262\u001b[0m )\n\u001b[1;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\MZC02-CHAESH\\miniconda3\\envs\\honglab-python\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:134\u001b[0m, in \u001b[0;36mOutputParser.parse\u001b[1;34m(self, response_text)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, response_text: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 134\u001b[0m     actual_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_all:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m actual_result\n",
      "File \u001b[1;32mc:\\Users\\MZC02-CHAESH\\miniconda3\\envs\\honglab-python\\Lib\\site-packages\\speech_recognition\\recognizers\\google.py:183\u001b[0m, in \u001b[0;36mOutputParser.convert_to_result\u001b[1;34m(response_text)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnknownValueError()\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# 인식기(Recognizer) 객체를 만듭니다.\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# 마이크 객체를 만듭니다. \n",
    "microphone = sr.Microphone(device_index=2)\n",
    "# microphone = sr.Microphone() # 대부분의 경우 device_index 생략 가능합니다.\n",
    "\n",
    "# 마이크로 음성을 녹음합니다.\n",
    "# with microphone as source는 microphone 객체를 사용할 준비를 시키고 \n",
    "# with-블럭 안에서 source라는 이름으로 사용하겠다는 의미입니다.\n",
    "# 어떤 자료형의 객체가 with문과 같이 사용될 수 있는지 아닌지는 \n",
    "# 미리 정해져 있기 때문에 보통 예제 코드를 참고해서 사용합니다.\n",
    "with microphone as source:\n",
    "    r.adjust_for_ambient_noise(source) # 배경 소음을 측정합니다.\n",
    "    print(\"음성 인식 대기중\")\n",
    "    audio = r.listen(source) # 일정 크기 이상의 소리가 들리면 녹음합니다.\n",
    "\n",
    "# with-as 블럭 안에서 정의한 변수인 audio를 블럭 밖에서도 사용할 수 있습니다.\n",
    "text = r.recognize_google(audio, language=\"ko\")\n",
    "\n",
    "print(\"인식 결과:\", text)\n",
    "\n",
    "# 음성을 제대로 인식하지 못하는 경우도 시연"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```raise UnknownValueError()``` 같은 예외 상황을 처리하기 위해 ```try-except-else```를 사용해보겠습니다.\n",
    "\n",
    "\n",
    "```try-except-else```는 프로그래머 입장에서 예측하기 어려운 예외적인 상황을 처리할 때 사용합니다. 주로 파일처리나 인터넷 연결과 같이 하드웨어와 관련된 상황에서 사용합니다. ```except```문은 예외의 종류에 따라 여러번 사용할 수도 있습니다. 예외의 종류에 대해서는 미리 정해져있기 때문에 대부분의 경우 예제 코드를 참고해서 구현합니다.\n",
    "\n",
    "```\n",
    "try:\n",
    "    일단 실행해볼 명령문 블럭\n",
    "except:\n",
    "    예외적인 상황이 발생했을 때 실행할 명령문 블럭\n",
    "else:\n",
    "    예외가 발생하지 않았을 때 실행할 명령문 블럭\n",
    "finally:\n",
    "    예외 발생과 상관 없이 실행할 명령문 블럭\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "microphone = sr.Microphone(device_index=2)\n",
    "\n",
    "while True:\n",
    "    with microphone as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        print(\"음성 인식 대기중\")\n",
    "        audio = r.listen(source)\n",
    "\n",
    "        try:\n",
    "            text = r.recognize_google(audio, language=\"ko\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"인식할 수 없습니다.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"인식에 문제가 있습니다.\", e)\n",
    "        else :\n",
    "            print(f\"인식 결과 : {text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [실습] '종료'라고 얘기하면 종료가 되도록 기능을 추가해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "microphone = sr.Microphone()\n",
    "\n",
    "# 여기에 구현\n",
    "while True:\n",
    "    with microphone as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        print(\"음성 인식 대기중\")\n",
    "        audio = r.listen(source)\n",
    "\n",
    "        try:\n",
    "            text = r.recognize_google(audio, language=\"ko\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"인식할 수 없습니다.\")\n",
    "        except sr.RequestError as e:\n",
    "            print(\"인식에 문제가 있습니다.\", e)\n",
    "        else :\n",
    "            print(f\"인식 결과 : {text}\")\n",
    "            if text == \"종료\":\n",
    "                break\n",
    "\n",
    "print(\"종료하였습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고] ```r.record()```를 이용해서 정해진 시간 동안 녹음을 할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# initialize the recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"앞으로 5초 동안 녹음합니다.\")\n",
    "    audio_data = r.record(source, duration=5)\n",
    "\n",
    "print(\"녹음이 완료되었습니다. 인식을 시작합니다.\")\n",
    "try:\n",
    "    text = r.recognize_google(audio_data, language=\"ko\")\n",
    "except:  # 다양한 예외들을 통틀어서 except 하나로 처리할 수도 있습니다.\n",
    "    print(\"음성이 인식되지 않았습니다.\")\n",
    "else:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[참고] 아래와 같이 ```sr.AudioFile()```을 이용해서 음성 파일을 읽어들여서 인식할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile(\"audio_sample.wav\") as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "try:\n",
    "    text = r.recognize_google(audio, language=\"ko\")\n",
    "except:\n",
    "    print(\"음성이 인식되지 않았습니다.\")\n",
    "else:\n",
    "    print(text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "23b62ad96709ddd91a685ddbb1f2ca1ce8bc759f31d2ce32b0006ee49d1f7faf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
