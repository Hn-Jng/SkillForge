{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# 상위 경로의 open_api_key를 가져오기 위한 코드\n",
    "env_path = os.path.join('..', '.env')\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# llm model 객체 생성\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "# momory 객체 생성\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    # memory_key=\"chat_history\", default memory_key가 history 이기 때문에 이건 제외하고 이후 코드에서 history를 변수로 사용\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "# prompt 생성\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "'''================================================================'''\n",
    "''' LLMChain을 통한 chain 실습\n",
    "-> off the shelf chain (자동으로 LLM으로부터 응답값을 가져오고 memory 저장 - 하지만 MessagesPlaceholder 를 프롬프트에 추가 필요)'''\n",
    "# chain = LLMChain(\n",
    "#     llm=llm,\n",
    "#     memory=memory,\n",
    "#     prompt=prompt,\n",
    "#     verbose=True,\n",
    "# )\n",
    "# chain.predict(question=\"My name is Hyunjoong\")\n",
    "\n",
    "'''================================================================'''\n",
    "'''Custom chain 실습'''\n",
    "\n",
    "def load_memory(_):\n",
    "    print(f\"load_memory 함수 input: {_}\")\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)\n",
    "    \n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_memory 함수 input: {'question': 'Hi, My name is Hanni'}\n",
      "content='Hello Hanni! How can I assist you today?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Hi, My name is Hanni\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_memory 함수 input: {'question': 'Do you have any suggestions for dinner?'}\n",
      "content='Sure! What type of cuisine are you in the mood for?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Do you have any suggestions for dinner?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_memory 함수 input: {'question': 'korean food or Italian food?'}\n",
      "content='Both Korean and Italian cuisines offer delicious options. For Korean food, you could try making bibimbap, bulgogi, or kimchi fried rice. For Italian food, you could make spaghetti carbonara, chicken parmesan, or a classic margherita pizza. Which one sounds more appealing to you?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"korean food or Italian food?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_memory 함수 input: {'question': 'what is my name?'}\n",
      "content='Your name is Hanni. How can I assist you further today, Hanni?'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='Hanni introduces themselves to the AI. The AI greets Hanni and asks how it can assist them today, suggesting dinner options based on the type of cuisine Hanni is in the mood for.'),\n",
       "  HumanMessage(content='korean food or Italian food?'),\n",
       "  AIMessage(content='Both Korean and Italian cuisines offer delicious options. For Korean food, you could try making bibimbap, bulgogi, or kimchi fried rice. For Italian food, you could make spaghetti carbonara, chicken parmesan, or a classic margherita pizza. Which one sounds more appealing to you?'),\n",
       "  HumanMessage(content='what is my name?'),\n",
       "  AIMessage(content='Your name is Hanni. How can I assist you further today, Hanni?')]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
